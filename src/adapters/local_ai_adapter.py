"""
Adapter LOCAL para clasificaci√≥n de art√≠culos usando modelos de Hugging Face.
Sin API keys, sin l√≠mites, completamente offline despu√©s de la primera descarga.
"""

from abc import ABC, abstractmethod
from typing import List, Tuple
import os


class AIServiceAdapter(ABC):
    """Interfaz abstracta para servicios de IA"""
    
    @abstractmethod
    def categorize_article(self, title: str, description: str, base_category: str) -> Tuple[str, str, str, str]:
        """Categoriza un art√≠culo en la jerarqu√≠a de 5 niveles"""
        pass
    
    @abstractmethod
    def extract_entities(self, title: str, description: str) -> List[str]:
        """Extrae entidades nombradas del texto"""
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """Verifica si el servicio est√° disponible"""
        pass


class LocalHuggingFaceAdapter(AIServiceAdapter):
    """
    Implementaci√≥n LOCAL usando Hugging Face Transformers.
    - Sin API keys
    - Sin l√≠mites de rate
    - Funciona offline despu√©s de la primera descarga
    - Perfecto para GitHub Actions
    """
    
    def __init__(self):
        self._available = False
        self.categorizer = None
        self.ner_pipeline = None
        
        try:
            from transformers import pipeline
            import torch
            
            print("ü§ñ Inicializando modelos locales de Hugging Face...")
            
            # Modelo para categorizaci√≥n de texto (multilingual)
            # Usamos un modelo peque√±o y r√°pido para clasificaci√≥n zero-shot
            self.categorizer = pipeline(
                "zero-shot-classification",
                model="facebook/bart-large-mnli",  # Modelo que entiende espa√±ol
                device=0 if torch.cuda.is_available() else -1  # GPU si est√° disponible
            )
            
            # Modelo para extracci√≥n de entidades (NER)
            self.ner_pipeline = pipeline(
                "ner",
                model="dslim/bert-base-NER",  # Modelo ligero para NER
                device=0 if torch.cuda.is_available() else -1
            )
            
            self._available = True
            print("‚úÖ Modelos locales listos (sin l√≠mites, sin API keys)")
            
        except ImportError:
            print("‚ùå Instalar: pip install transformers torch")
            self._available = False
        except Exception as e:
            print(f"‚ùå Error inicializando modelos: {e}")
            self._available = False
    
    def categorize_article(self, title: str, description: str, base_category: str) -> Tuple[str, str, str, str]:
        """Categoriza usando zero-shot classification"""
        if not self.is_available():
            raise Exception("Modelos locales no disponibles")
        
        text = f"{title}. {description or ''}"[:512]  # L√≠mite del modelo
        
        # Categor√≠as principales
        categories = [
            "Pol√≠tica", "Deportes", "Espect√°culos", "Econom√≠a", 
            "Sociedad", "Cultura", "Tecnolog√≠a", "Internacional",
            "Salud", "Educaci√≥n", "Seguridad", "Medio Ambiente"
        ]
        
        # Subcategor√≠as por categor√≠a principal
        subcategories_map = {
            "Pol√≠tica": ["Poder Ejecutivo", "Congreso", "Elecciones", "Corrupci√≥n", "Gobierno Regional"],
            "Deportes": ["F√∫tbol Nacional", "F√∫tbol Internacional", "Otros Deportes", "Selecci√≥n Peruana"],
            "Espect√°culos": ["Far√°ndula", "Cine", "M√∫sica", "Televisi√≥n", "Teatro"],
            "Econom√≠a": ["Finanzas", "Empresas", "Mercados", "Empleo", "Impuestos"],
        }
        
        try:
            # Paso 1: Clasificar categor√≠a principal
            result = self.categorizer(text, categories, multi_label=False)
            category = result['labels'][0] if result['scores'][0] > 0.3 else base_category
            
            # Paso 2: Clasificar subcategor√≠a
            subcategories = subcategories_map.get(category, ["General"])
            subcat_result = self.categorizer(text, subcategories, multi_label=False)
            subcategory = subcat_result['labels'][0] if subcat_result['scores'][0] > 0.3 else "General"
            
            # Paso 3: Extraer tema principal (primeras palabras clave del t√≠tulo)
            theme = self._extract_theme(title)
            
            # Paso 4: Subtema (basado en palabras clave del texto)
            subtema = self._extract_subtema(description or title)
            
            return (category, subcategory, theme, subtema)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en categorizaci√≥n local: {e}")
            return (base_category, "General", "General", "General")
    
    def extract_entities(self, title: str, description: str) -> List[str]:
        """Extrae entidades usando NER local"""
        if not self.is_available():
            raise Exception("Modelos locales no disponibles")
        
        text = f"{title}. {description or ''}"[:512]
        
        try:
            # Extraer entidades con NER
            entities = self.ner_pipeline(text)
            
            # Filtrar y limpiar entidades
            entity_names = []
            for entity in entities:
                if entity['score'] > 0.8:  # Solo entidades con alta confianza
                    name = entity['word'].replace('##', '').strip()
                    if len(name) > 2:
                        entity_names.append(name.lower().replace(' ', '_'))
            
            # Eliminar duplicados y retornar top 10
            return list(set(entity_names))[:10]
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en extracci√≥n de entidades: {e}")
            return []
    
    def _extract_theme(self, title: str) -> str:
        """Extrae el tema principal del t√≠tulo (primeras 3-4 palabras significativas)"""
        words = title.split()
        # Filtrar palabras cortas y stopwords
        significant = [w for w in words if len(w) > 3][:3]
        return ' '.join(significant) if significant else "General"
    
    def _extract_subtema(self, text: str) -> str:
        """Extrae subtema (palabras clave del texto)"""
        words = text.split()
        significant = [w for w in words if len(w) > 4][:2]
        return ' '.join(significant) if significant else "General"
    
    def is_available(self) -> bool:
        return self._available and self.categorizer is not None


class AIServiceFactory:
    """Factory para crear el adapter apropiado"""
    
    @staticmethod
    def create_adapter(provider: str = "local", **kwargs) -> AIServiceAdapter:
        """
        Crea un adapter seg√∫n el proveedor especificado
        
        Args:
            provider: 'local' (Hugging Face, recomendado y gratuito)
        """
        if provider.lower() == "local":
            return LocalHuggingFaceAdapter()
        else:
            raise ValueError(f"Proveedor no soportado: {provider}. Usa: local")
